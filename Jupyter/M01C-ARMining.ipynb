{
    "metadata": {
        "language_info": {
            "name": "python", 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 3
            }, 
            "file_extension": ".py", 
            "version": "3.5.2"
        }, 
        "anaconda-cloud": {}, 
        "kernelspec": {
            "display_name": "Python 3.5 (Experimental) with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "metadata": {}, 
            "source": "# Modern Data Science \n**(Module 01: A Touch of Data Science)**\n\n---\n- Materials in this module include resources collected from various open-source online repositories.\n- You are free to use, change and distribute this package.\n\nPrepared by and for \n**Student Members** |\n2006-2018 [TULIP Lab](http://www.tulip.org.au), Australia\n\n---\n\n\n# Session C - Association Rule Mining", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "Import the package", 
            "cell_type": "markdown"
        }, 
        {
            "source": "from numpy import *", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "Creat a simple data set to test", 
            "cell_type": "markdown"
        }, 
        {
            "source": "def loadDataSet():\n    return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "The function  createC1() creates\u2014you guessed it\u2014 C1 .  C1 is a candidate itemset of size one.\nIn the Apriori algorithm, we create  C1 , and then we\u2019ll scan the dataset to see\nif these one itemsets meet our minimum support requirements. The itemsets that do\nmeet our minimum requirements become  L1 .  L1 then gets combined to become  C2\nand  C2 will get filtered to become  L2 . This is the main idea of this lgorithm.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "def createC1(dataSet):\n    C1 = []\n    for transaction in dataSet:\n        for item in transaction:\n            if not [item] in C1:\n                C1.append([item])\n                \n    C1.sort()\n    return map(frozenset, C1)#use frozen set so we\n                            #can use it as a key in a dict ", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "This function(scanD) takes three arguments: a dataset,  Ck , a list of candidate sets, and  minSupport , which is the minimum\nsupport you\u2019re interested in. This is the function you\u2019ll use to generate  L1 from  C1.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "def scanD(D, Ck, minSupport):\n    ssCnt = {}\n    for tid in D:\n        for can in Ck:\n            if can.issubset(tid):\n                if can not in ssCnt.keys(): ssCnt[can]=1\n                else: ssCnt[can] += 1\n    numItems = float(len(list(D)))\n    retList = []\n    supportData = {}\n    for key in ssCnt:\n        support = ssCnt[key]/numItems\n        if support >= minSupport:\n            retList.insert(0,key)\n        supportData[key] = support\n    return retList, supportData", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# !pip install apriori\n!pip install apyori", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# import apriori\nfrom apyori import apriori", 
            "metadata": {
                "scrolled": true
            }, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "dataSet = loadDataSet()\nprint(dataSet)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "C1 = createC1(dataSet)\n# for i in list(C1):\n#     print(i)\nlisC=list(C1)\nprint(lisC)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "D = map(set, dataSet)\nlisD=list(D)\nprint(lisD)\nprint(type(lisD[0]))\nprint (len(lisD))\nfor i in lisD:\n    print(i)\n\n# print(type(list(D)[0]))", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "L1,suppData0 = scanD(lisD, lisC, 0.5)\nprint (L1)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "The function  aprioriGen() will take a list of frequent itemsets, Lk , and the size of the itemsets,  k , to produce  Ck . For example, it will take the itemsets {0}, {1}, {2} and so on and produce {0,1} {0,2}, and {1,2}.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "def aprioriGen(Lk, k): #creates Ck\n    retList = []\n    lenLk = len(Lk)\n    for i in range(lenLk):\n        for j in range(i+1, lenLk): \n            L1 = list(Lk[i])[:k-2]; L2 = list(Lk[j])[:k-2]\n            L1.sort(); L2.sort()\n            if L1==L2: #if first k-2 elements are equal\n                retList.append(Lk[i] | Lk[j]) #set union\n    return retList", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "def apriori(dataSet, minSupport = 0.5):\n    C1 = createC1(dataSet)\n    D = map(set, dataSet)\n    L1, supportData = scanD(lisD, lisC, minSupport)\n    L = [L1]\n    k = 2\n    while (len(L[k-2]) > 0):\n        Ck = aprioriGen(L[k-2], k)\n        Lk, supK = scanD(lisD, Ck, minSupport)#scan DB to get Lk\n        supportData.update(supK)\n        L.append(Lk)\n        k += 1\n    return L, supportData", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "L,suppData = apriori(dataSet)\nprint (L)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "L[0]", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "L[1]", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "L[2]", 
            "metadata": {
                "scrolled": true
            }, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "L[3]", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "L,suppData = apriori(dataSet, minSupport=0.7)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "L", 
            "metadata": {
                "scrolled": true
            }, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "The function is going to generate a list of rules with confidence values that we can sort through later.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "def generateRules(L, supportData, minConf=0.7):  #supportData is a dict coming from scanD\n    bigRuleList = []\n    for i in range(1, len(L)):#only get the sets with two or more items\n        for freqSet in L[i]:\n            H1 = [frozenset([item]) for item in freqSet]\n            if (i > 1):\n                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n            else:\n                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n    return bigRuleList         ", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "The function is mainly to evaluate those rules.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "def calcConf(freqSet, H, supportData, brl, minConf=0.7):\n    prunedH = [] #create new list to return\n    for conseq in H:\n        conf = supportData[freqSet]/supportData[freqSet-conseq] #calc confidence\n        if conf >= minConf: \n            print (freqSet-conseq,'-->',conseq,'conf:',conf)\n            brl.append((freqSet-conseq, conseq, conf))\n            prunedH.append(conseq)\n    return prunedH", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "The function is to generate a set of candidate rules.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n    m = len(H[0])\n    if (len(freqSet) > (m + 1)): #try further merging\n        Hmp1 = aprioriGen(H, m+1)#create Hm+1 new candidates\n        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)\n        if (len(Hmp1) > 1):    #need at least two sets to merge\n            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "def pntRules(ruleList, itemMeaning):\n    for ruleTup in ruleList:\n        for item in ruleTup[0]:\n            print (itemMeaning[item])\n        print (\"           -------->\")\n        for item in ruleTup[1]:\n            print (itemMeaning[item])\n        print (\"confidence: %f\" % ruleTup[2])", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "L,suppData = apriori(dataSet, minSupport = 0.5)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "rules = generateRules(L, suppData, minConf = 0.7)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "rules", 
            "cell_type": "markdown"
        }, 
        {
            "source": "rules = generateRules(L, suppData, minConf = 0.5)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "rules", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "#### An Example: finding similar features in poisonous mushrooms", 
            "cell_type": "markdown"
        }, 
        {
            "source": "import wget\n\nlink_to_data = 'https://github.com/tuliplab/mds/raw/master/Jupyter/data/mushroom.dat'\nDataSet = wget.download(link_to_data)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "mushDatSet = [line.split() for line in open('mushroom.dat').readlines()]", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "L,suppData=apriori(mushDatSet, minSupport=0.3)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "for item in L[1]:\n    if item.intersection('2'): \n        print (item)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "for item in L[3]:\n    if item.intersection('2'): \n        print (item)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "#### Another Example: Market Basket", 
            "cell_type": "markdown"
        }, 
        {
            "source": "import wget\n\nlink_to_data = 'https://github.com/tuliplab/mds/raw/master/Jupyter/data/Market_Basket_Optimisation.csv'\nDataSet = wget.download(link_to_data)", 
            "metadata": {}, 
            "execution_count": 1, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# !pip install apyori", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "import pandas as pd\nfrom apyori import apriori", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "dataset = pd.read_csv('Market_Basket_Optimisation.csv', header = None)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "transactions = []\nfor i in range(0,len(dataset)):\n    currentItem = dataset.iloc[i,:].values\n#    print(currentItem)\n    currentTransaction = []\n#    print(currentTransaction)\n    for j in range(0,len(currentItem)):\n        currentTransaction.append(str(currentItem[j]))\n#    print(currentTransaction)\n    transactions.append(currentTransaction)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "rules = apriori(transactions, min_support = 0.003,min_confidence = 0.2,min_lift = 3,min_length = 2)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# Show the results\nresults = list(rules)\nprint(results)", 
            "metadata": {
                "scrolled": true
            }, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "for i in range(len(results)):\n    print(\"##############################################################################\")\n    print(i)\n    print(results[i])\n    print(results[i].items)\n    ", 
            "metadata": {
                "scrolled": false
            }, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }
    ], 
    "nbformat_minor": 2
}